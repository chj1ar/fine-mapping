{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Original discussion about `gene:line_number`\n",
    "\n",
    "really?  Another way would be to compute a priori the line number for each gene, save as a Python dictionary in SoS global variable,  then use sed to get to that specific line when you have a gene name -- does this big picture idea make sense? (edited)\n",
    "32 replies\n",
    "\n",
    "Jiarun  3 days ago\n",
    "really?\n",
    "Actually my command was zless *.gz | grep ENSG... > some.tmp.file, which took so long. However, I may not rule out the possibility of RCC causing that slow.\n",
    "\n",
    "Jiarun  3 days ago\n",
    "Another way would be to compute a priori the line number for each gene\n",
    "So the key is to run some code before the pipeline, which runs once per gene. (Let me try to think of a way first perhaps) (edited)\n",
    "\n",
    "gaow  3 days ago\n",
    "So the key is to run some code before the pipeline,\n",
    "yes, or rather, as a preprocessing step of the pipeline!\n",
    "which runs once per gene.\n",
    "No it runs once per y or z file\n",
    "\n",
    "gaow  3 days ago\n",
    "which is 2 * number of tissues total?\n",
    "\n",
    "gaow  3 days ago\n",
    "all you need is the first column of each file, the gene name, and then get their line number\n",
    "\n",
    "gaow  3 days ago\n",
    "i suggest you first learn to use filename control and derivation via SoS vairables; otherwise it will be a mess.\n",
    "\n",
    "Jiarun  3 days ago\n",
    "yes, or rather, as a preprocessing step of the pipeline!\n",
    "That’s a good idea!\n",
    "\n",
    "Jiarun  3 days ago\n",
    "No it runs once per y or z file\n",
    "I see you mean the grep ENSG... step. And the step of reading from files the expression of all 20000 genes can also be treated as preprocessing, right? I mean, in a separate preprocessing section in the SoS Notebook. (Please forgive my unfamiliarity with SoS) (edited)\n",
    "\n",
    "gaow  3 days ago\n",
    "the step of reading from files the expression of all 20000 genes can also be treated as preprocessing, right?\n",
    "you will not have this step if you get a list of gene:line_number\n",
    "\n",
    "gaow  3 days ago\n",
    "because you will sed that line number for the gene instead of grep\n",
    "\n",
    "Jiarun  3 days ago\n",
    "Oh. You mean using bash instead of R (or Python)! (edited)\n",
    "\n",
    "gaow  3 days ago\n",
    "so you always get one line of expression for the gene of interest. this is just a faster alternateive to grep.\n",
    "\n",
    "gaow  3 days ago\n",
    "Well good point, or you can figure out how to read a specific line in R rather than the whole file that will be even better!\n",
    "\n",
    "gaow  3 days ago\n",
    "maybe you google it and see. if so, then in R you first get the line number of interest, then use R to read that line. I believe at least you can \"read from standard output stream in R\" so you acn do read.xxx('sed ... ') in R\n",
    "\n",
    "gaow  3 days ago\n",
    "(google how to read standard stream in R if you cannot find how to read a line in R)\n",
    "\n",
    "Jiarun  2 days ago\n",
    "OK. I will search. But I suspect that directly reading all the 49 gene expression files as preprocessing and extracting gene expression for each gene by subsetting the huge variable of expression of all genes based on the prespecified gene:line_number would be faster than reading a specific line in R, mainly for my time of development, perhaps even in terms of running time. (edited)\n",
    "\n",
    "Jiarun  16 hours ago\n",
    "Gao, I think this problem is actually intrinsic. I mean, no matter which approach we use, the essential step is to search the location of a gene in a file with tissue-specific gene expressions, which takes some 1s in either bash grep or R grepl() or Python file IO, since the algorithm doesn’t seem to be able to improve.\n",
    "\n",
    "Jiarun  16 hours ago\n",
    "Oh wait, but even if it takes 1min to generate RDS for one gene, the whole procedure will still finish within 2h, which I can definitely bear. So is that OK? (edited)\n",
    "\n",
    "gaow  12 hours ago\n",
    "Did you try how long it takes if you know the line number ? No grep is involved ...\n",
    "\n",
    "gaow  12 hours ago\n",
    "Would be helpful if you read my earlier suggestions again in case you didn't fully understand it?\n",
    "\n",
    "Jiarun  12 hours ago\n",
    "OK. I will read them again.\n",
    "\n",
    "Jiarun  12 hours ago\n",
    "I didn’t find anything new …\n",
    "\n",
    "Jiarun  12 hours ago\n",
    "But grep is actually included in the process of generating gene:line_number, I mean, at least each file has to be traversed. (edited)\n",
    "\n",
    "gaow  12 hours ago\n",
    "@Jiarun can you just read the first column (in Python pandas) the gene names, then assign line numbers to them, for each tissue?\n",
    "\n",
    "gaow  12 hours ago\n",
    "once you have gene:lin_number you can sed or other methods to read a line, which should be fast -- is this part clear?\n",
    "\n",
    "Jiarun  12 hours ago\n",
    "Oh! I find the message above! I was too careless!\n",
    "\n",
    "Jiarun  12 hours ago\n",
    "(Actually when I calculated the complexity to see why it takes ~1min, I saw that traversing the whole files is highly unnecessary, but I just failed to think of extracting gene names first!\n",
    "\n",
    "\n",
    "Jiarun  12 hours ago\n",
    "I have tested reading specific line by sed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Crystallized plan for generating y with the main step `gene:line_number`\n",
    "\n",
    "1) extract the column of ensembl_gene_id in the 49 expression files by `pandas`\n",
    "\n",
    "2) assign `gene:line_number` for each gene in each tissue based on the extracted column just now\n",
    "\n",
    "3) for each gene, extract the row of expression of the gene with sample names in each tissue using `sed`\n",
    "\n",
    "4) that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# preprocessing: prepare gene expressions, gene TSS.\n",
    "[preprocessing]\n",
    "depends: R_library(\"biomaRt\"), R_library(\"data.table\")\n",
    "\n",
    "bash: expand = '${ }'\n",
    "    # `ensembl_gene_id.txt`\n",
    "    cd /project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/eqtl/GTEx_Analysis_v8_eQTL_expression_matrices\n",
    "    for file in ./*.gz; do zless \"$file\" | grep -oh \"ENSG\\w*\\.\\w*\" >> /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/ensembl_gene_id_original.txt ; done\n",
    "    cd /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/\n",
    "    sort -u ensembl_gene_id_original.txt > ensembl_gene_id.txt\n",
    "    rm ensembl_gene_id_original.txt\n",
    "    \n",
    "    # `samplenames_X.txt`\n",
    "    zless /project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/genotypes/WGS/variant_calls/GTEx_Analysis_2017-06-05_v8_WholeGenomeSeq_838Indiv_Analysis_Freeze.SHAPEIT2_phased.vcf.gz | sed '3386q;d' > /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/samplenames_X.txt\n",
    "\n",
    "python3: expand = '${ }'\n",
    "    # `gene:line_number`\n",
    "    \n",
    "    filenames_y = glob.glob(\"/Users/cjr/Documents/Enloc/eQTL/GTEx_Analysis_v8_eQTL_expression_matrices/*.gz\")\n",
    "    filenames_y.sort()\n",
    "    gene_linenumber = {} # Now gene_linenumber is a list of 49 dict, each of which has 20000 items. But if gene_linenumber is a dict of 20000 dict, each of which has 49 items, then it can be saved into 20000 files!\n",
    "    fields = ['gene_id', ]\n",
    "    for j in range(len(ensembl_gene_id)): # construct ~20000 dict, each of which has 49 items\n",
    "        gene_linenumber[ensembl_gene_id[j]] = {}\n",
    "\n",
    "    for i in range(len(filenames_y)): # construct each of the 49 `gene:line_number`\n",
    "        gene_id = pd.read_csv(filenames_y[i], sep='\\t', skipinitialspace=True, usecols=fields)\n",
    "        for j in range(gene_id.shape[0]): # go over lines\n",
    "            gene_linenumber[gene_id['gene_id'].tolist()[j]][i] = j + 2\n",
    "            print('%s at line %d in file %d' % (gene_id['gene_id'].tolist()[j], j + 2, i))\n",
    "    \n",
    "    import csv\n",
    "    for j in range(len(gene_linenumber)): # write ~20000 files\n",
    "        with open(('/Users/cjr/Documents/Enloc/eQTL/gene-line_number/%s.csv' % ensembl_gene_id[j]), 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for key, value in gene_linenumber[ensembl_gene_id[j]].items():\n",
    "                writer.writerow([key, value])\n",
    "    \n",
    "    # Now gene_linenumber is a list of 49 dict, each of which has 20000 items. But if gene_linenumber is a dict of 20000 dict, each of which has 49 items, then it can saved into 20000 files!\n",
    "#     filenames_y = glob.glob(\"/Users/cjr/Documents/Enloc/eQTL/GTEx_Analysis_v8_eQTL_expression_matrices/*.gz\")\n",
    "#     filenames_y.sort()\n",
    "#     gene_linenumber = []\n",
    "#     fields = ['gene_id', ]\n",
    "#     for i in range(len(filenames_y)): # create 49 `gene:line_number`\n",
    "#         gene_linenumber.append({})\n",
    "\n",
    "#     for i in range(len(filenames_y)): # construct each of the 49 `gene:line_number`\n",
    "#         gene_id = pd.read_csv(filenames_y[i], sep='\\t', skipinitialspace=True, usecols=fields)\n",
    "#         for j in range(gene_id.shape[0]): # go over lines\n",
    "#             gene_linenumber[i][gene_id['gene_id'].tolist()[j]] = j + 2\n",
    "#             print('%s at line %d in file %d' % (gene_id['gene_id'].tolist()[j], j + 2, i))\n",
    "\n",
    "    # stupid! why not directly go instead of search over ensembl_gene_id?!\n",
    "#     with open(\"/scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/ensembl_gene_id.txt\") as f:\n",
    "#         ensembl_gene_id = [line.rstrip(\"\\n\") for line in f]\n",
    "\n",
    "#     filenames_y = glob.glob(\"/project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/eqtl/GTEx_Analysis_v8_eQTL_expression_matrices/*.gz\")\n",
    "#     gene_linenumber = []\n",
    "#     fields = ['gene_id', ]\n",
    "#     for i in range(len(filenames_y)): # create 49 dict of `gene:line_number`\n",
    "#         gene_linenumber.append({})\n",
    "    \n",
    "#     for i in range(len(filenames_y)): # construct each of the 49 `gene:line_number`\n",
    "#         gene_id = pd.read_csv(filenames_y[i], sep='\\t', skipinitialspace=True, usecols=fields)\n",
    "#         for j in range(len(ensembl_gene_id)): # search over ensembl_gene_id (turns out to be extremely stupid!)\n",
    "#             if (gene_id.loc[gene_id['gene_id'] == ensembl_gene_id[j]].shape[0] == 0):\n",
    "#                 continue\n",
    "#             number = gene_id.loc[gene_id['gene_id'] == ensembl_gene_id[j]].index[0] + 2\n",
    "#             gene_linenumber[i][ensembl_gene_id[j]] = number\n",
    "#             print('found ensembl_gene_id[%d] = %s in line %d of file %d' % (j, ensembl_gene_id[j], number, i))\n",
    "    \n",
    "\n",
    "    # the following code is abandoned! Remember Gao Wang's words!!!\n",
    "#     gene_linenumber = {} # `gene:line_number`\n",
    "#     import gzip\n",
    "#     for i in range(len(ensembl_gene_id)): # search over genes\n",
    "#         with gzip.open(\"/project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/eqtl/GTEx_Analysis_v8_eQTL_expression_matrices/Adipose_Subcutaneous.v8.normalized_expression.bed.gz\") as f: # construct `gene:line_number` for each tissue respectively\n",
    "#             for number, line in enumerate(f, 1): # search the gene in the file\n",
    "#                 if ensembl_gene_id[i].encode() in line: # once match, record it into `gene:line_number` and proceed to the next gene\n",
    "#                     print('found ensembl_gene_id[%d] = %s in line %d.' % (i, ensembl_gene_id[i], number))\n",
    "#                     gene_linenumber[ensembl_gene_id[i]] = number\n",
    "#                     break\n",
    "    \n",
    "R: expand = True\n",
    "    # `gene_TSS.csv`\n",
    "    ensembl_gene_id <- fread(file = \"/scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/ensembl_gene_id.txt\", sep = \"\\n\", quote = \"\", header = FALSE)\n",
    "    gene_TSS <- getBM(attributes = c(\"chromosome_name\", \"transcript_start\", \"ensembl_gene_id\", \"ensembl_gene_id_version\"), filters = \"ensembl_gene_id_version\", values = ensembl_gene_id, mart = mart)\n",
    "    rm(ensembl_gene_id)\n",
    "    write.table(x = gene_TSS, file = \"/scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/gene_TSS.csv\", sep = '\\t', quote = FALSE, col.names = TRUE, row.names = FALSE)\n",
    "    # gene_TSS_retrieval <- read.table(file = \"/scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/gene_TSS.csv\", sep = '\\t', quote = \"\", stringsAsFactors = FALSE, header = TRUE)\n",
    "    \n",
    "    # prepare expression of all the 20000 genes in each tissue and the directory for query.\n",
    "    filenames_y <- list.files(path = \"/project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/eqtl/GTEx_Analysis_v8_eQTL_expression_matrices\", pattern = \"*.gz$\", full.names = TRUE) # expression of 20000 genes in 49 tissues (49 files)\n",
    "    read_expression <- function(x) {{\n",
    "        y_allgenes_tmp <- scan(file = x, what = \"\", sep = \"\\n\")\n",
    "        y_allgenes <- strsplit(x = y_allgenes_tmp, split = \"[[:space:]]+\") # The most time-consuming step\n",
    "        return(y_allgenes)\n",
    "    }}\n",
    "    y_total <- lapply(filenames_y, read_expression)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# extract Z, y, X from covariates, expression and genotype data and generate y_res\n",
    "[extract]\n",
    "parameter: ensembl_gene_id = str\n",
    "bash: expand = '${ }'\n",
    "    # y\n",
    "#     zless /project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/eqtl/GTEx_Analysis_v8_eQTL_expression_matrices/*.gz | grep -w \"${ensembl_gene_id}\" > /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/${ensembl_gene_id}.txt\n",
    "    \n",
    "    # X\n",
    "    awk '$4 ~ /{ensembl_gene_id}/ {{print $0}}' /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/gene_TSS.csv | head -n 1 | awk '{{$3=$2+1000000}} {{$2=$2-1000000}} {{print \"chr\"$1\":\"$2\"-\"$3}}' > /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/{ensembl_gene_id}_TSSregion.txt\n",
    "    tabix /project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/genotypes/WGS/variant_calls/GTEx_Analysis_2017-06-05_v8_WholeGenomeSeq_838Indiv_Analysis_Freeze.SHAPEIT2_phased.vcf.gz \"$(< /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/{ensembl_gene_id}_TSSregion.txt)\" | sed -e 's/0|0/0/g' -e 's/0|1/1/g' -e 's/1|0/1/g' -e 's/1|1/2/g' > /scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/{ensembl_gene_id}_genotype.txt\n",
    "    \n",
    "R: expand = True\n",
    "    # Z\n",
    "    filenames <- list.files(path = \"/project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/eqtl/GTEx_Analysis_v8_eQTL_covariates\", pattern = \"*.txt\", full.names = TRUE)\n",
    "    Z <- lapply(filenames, function(x) t(as.matrix(read.table(file = x, header = TRUE, sep = '\\t', quote = \"\", row.names = 1))))\n",
    "    for (i in 1:49) {{ # the format of sample names Z was changed somehow, from \"GTEX-*\" to \"GTEX.*\", so we need to convert it back.\n",
    "        rownames(Z[[i]]) <- gsub(pattern = \"GTEX.\", replacement = \"GTEX-\", x = rownames(Z[[i]]))\n",
    "    }}\n",
    "    \n",
    "    # y\n",
    "    \n",
    "    filenames_y <- list.files(path = \"/project/compbio/GTEx_dbGaP/GTEx_Analysis_2017-06-05_v8/eqtl/GTEx_Analysis_v8_eQTL_expression_matrices\", pattern = \"*.gz$\", full.names = TRUE)\n",
    "    extract_y <- function(i) {{\n",
    "        yi <- fread(file = filenames_y[i], skip = line_numbers[i,] - 1, nrows = 1)\n",
    "        samplenames_yi <- fread(file = filenames_y[i], skip = 0, nrows = 1)\n",
    "        colnames(yi) <- colnames(samplenames_yi)\n",
    "        yi <- t(as.matrix(yi))\n",
    "        yi <- yi[-1:-4, , drop = FALSE]\n",
    "        return(yi)\n",
    "    }}\n",
    "    \n",
    "    y <- lapply(1:49, extract_y)\n",
    "    \n",
    "    ## sample names matching between y and Z\n",
    "    samplenamesmatching <- function(x, reference) {{\n",
    "        lapply(1:49, function(i) x[[i]][match(rownames(reference[[i]]), rownames(x[[i]])), , drop = FALSE])\n",
    "    }}\n",
    "    \n",
    "    y_matchZ <- samplenamesmatching(x = y, reference = Z)\n",
    "    y <- y_matchZ\n",
    "    \n",
    "    # X\n",
    "    X <- read.csv(file = \"/scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/{ensembl_gene_id}_genotype.txt\", sep = '\\t', header = FALSE, row.names = 3, stringsAsFactors = FALSE)\n",
    "    X <- X[,-(1:8)]\n",
    "    samplenames_X <- scan(file = \"/scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/samplenames_X.txt\", what = character(), quote = \"\")\n",
    "    samplenames_X <- samplenames_X[-(1:9)]\n",
    "    colnames(X) <- samplenames_X\n",
    "    X <- as.matrix(x = X)\n",
    "    X <- t(X)\n",
    "    \n",
    "    # y_res\n",
    "    y_res <- lapply(1:49, function(i) .lm.fit(x = Z[[i]], y = y[[i]])$residuals)\n",
    "\n",
    "    # save\n",
    "    saveRDS(object = list(X = X, y = y, Z = Z, y_res = y_res), file = \"/scratch/midway2/chj1ar/GTEx_Analysis_v8_eQTL_expression_genewise/Multi_Tissues.{ensembl_gene_id}.RDS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.19.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
